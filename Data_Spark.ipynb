{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSpark : Illuminating Insights for Global Electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load raw dataset\n",
    "raw_customers = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\Customers.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# EDA on Raw Data\n",
    "print(\"EDA on Raw Data\")\n",
    "print(raw_customers.info())\n",
    "print(raw_customers.head())\n",
    "print(raw_customers.describe(include='all'))\n",
    "print(raw_customers.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Gender Distribution (Raw Data)\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.countplot(x='Gender', data=raw_customers)\n",
    "plt.title('Customer Gender Distribution (Raw Data)')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# 2. City Distribution (Top 10 Cities) (Raw Data)\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.countplot(y='City', data=raw_customers, order=raw_customers['City'].value_counts().index[:10])\n",
    "plt.title('Top 10 Cities by Customer Count (Raw Data)')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('City')\n",
    "\n",
    "# 3. State Distribution (Raw Data)\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.countplot(y='State', data=raw_customers, order=raw_customers['State'].value_counts().index)\n",
    "plt.title('State Distribution by Customer Count (Raw Data)')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('State')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "# Handling Missing Values\n",
    "raw_customers['City'].fillna('Unknown', inplace=True)\n",
    "raw_customers['State'].fillna('Unknown', inplace=True)\n",
    "raw_customers['State Code'].fillna('Unknown', inplace=True)  \n",
    "raw_customers['Zip Code'].fillna(0, inplace=True)\n",
    "raw_customers['Country'].fillna('Unknown', inplace=True)\n",
    "raw_customers['Continent'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Correcting Data Types\n",
    "raw_customers['Birthday'] = pd.to_datetime(raw_customers['Birthday'], errors='coerce')\n",
    "\n",
    "# Removing Duplicates (excluding primary key and unique key)\n",
    "cleaned_customers = raw_customers.drop_duplicates(subset=[col for col in raw_customers.columns if col not in ['CustomerKey']])\n",
    "\n",
    "# Renaming Columns for Consistency\n",
    "cleaned_customers.rename(columns={'CustomerKey': 'Customer_ID', 'Zip Code': 'Zip_Code', 'State Code': 'State_Code'}, inplace=True)\n",
    "\n",
    "# Handling Categorical Data\n",
    "cleaned_customers['Gender'] = cleaned_customers['Gender'].astype('category')\n",
    "\n",
    "# Calculate Age\n",
    "cleaned_customers['Age'] = (pd.Timestamp.now() - cleaned_customers['Birthday']).dt.total_seconds() / (60*60*24*365.25)\n",
    "cleaned_customers['Age'] = cleaned_customers['Age'].astype(int)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_customers.to_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_customers.csv', index=False)\n",
    "\n",
    "print(\"Customers data cleaning completed.\")\n",
    "\n",
    "# Load cleaned dataset\n",
    "customers = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_customers.csv')\n",
    "\n",
    "# EDA on Cleaned Data\n",
    "print(\"EDA on Cleaned Data\")\n",
    "print(customers.info())\n",
    "print(customers.head())\n",
    "print(customers.describe(include='all'))\n",
    "print(customers.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# 1. Age Distribution (Cleaned Data)\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.histplot(customers['Age'], bins=20, kde=True)\n",
    "plt.title('Customer Age Distribution (Cleaned Data)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Gender Distribution (Cleaned Data)\n",
    "plt.subplot(3, 2, 2)\n",
    "sns.countplot(x='Gender', data=customers)\n",
    "plt.title('Customer Gender Distribution (Cleaned Data)')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# 3. City Distribution (Top 10 Cities) (Cleaned Data)\n",
    "plt.subplot(3, 2, 3)\n",
    "sns.countplot(y='City', data=customers, order=customers['City'].value_counts().index[:10])\n",
    "plt.title('Top 10 Cities by Customer Count (Cleaned Data)')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('City')\n",
    "\n",
    "# 4. State Distribution (Cleaned Data)\n",
    "plt.subplot(3, 2, 4)\n",
    "sns.countplot(y='State', data=customers, order=customers['State'].value_counts().index)\n",
    "plt.title('State Distribution by Customer Count (Cleaned Data)')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('State')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional Plots (Cleaned Data)\n",
    "\n",
    "# 5. Age by Gender\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Gender', y='Age', data=customers)\n",
    "plt.title('Age Distribution by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# 6. Age by State (Top 10 States by Customer Count)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(y='State', x='Age', data=customers, order=customers['State'].value_counts().index[:10])\n",
    "plt.title('Age Distribution by State')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('State')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load raw dataset\n",
    "raw_sales = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\Sales.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# EDA on Raw Data\n",
    "print(\"EDA on Raw Data\")\n",
    "print(raw_sales.info())\n",
    "print(raw_sales.head())\n",
    "print(raw_sales.describe(include='all'))\n",
    "print(raw_sales.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 10))  # Adjusted figure size to fit fewer plots\n",
    "\n",
    "# 1. Quantity Distribution (Raw Data)\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(raw_sales['Quantity'].dropna(), bins=20, kde=True)\n",
    "plt.title('Quantity Distribution (Raw Data)')\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Sales by Product (Top 10 Products) (Raw Data)\n",
    "plt.subplot(2, 2, 2)\n",
    "if 'ProductKey' in raw_sales.columns:\n",
    "    sns.countplot(y='ProductKey', data=raw_sales, order=raw_sales['ProductKey'].value_counts().index[:10])\n",
    "    plt.title('Top 10 Products by Sales Count (Raw Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Product')\n",
    "else:\n",
    "    print(\"Column 'ProductKey' is not present in the raw dataset.\")\n",
    "\n",
    "# 3. Sales by Store (Top 10 Stores) (Raw Data)\n",
    "plt.subplot(2, 2, 3)\n",
    "if 'StoreKey' in raw_sales.columns:\n",
    "    sns.countplot(y='StoreKey', data=raw_sales, order=raw_sales['StoreKey'].value_counts().index[:10])\n",
    "    plt.title('Top 10 Stores by Sales Count (Raw Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Store')\n",
    "else:\n",
    "    print(\"Column 'StoreKey' is not present in the raw dataset.\")\n",
    "\n",
    "# Remove redundant plot for Sales Value Distribution (Raw Data)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "# Define primary and unique key columns\n",
    "primary_keys_sales = ['Order Number', 'Line Item', 'CustomerKey', 'StoreKey', 'ProductKey']\n",
    "\n",
    "# Handling Missing Values\n",
    "raw_sales.dropna(subset=['Order Date'], inplace=True)\n",
    "\n",
    "# Correcting Data Types\n",
    "raw_sales['Order Date'] = pd.to_datetime(raw_sales['Order Date'], errors='coerce')\n",
    "\n",
    "# Handling Outliers (e.g., capping extreme values in Quantity)\n",
    "raw_sales['Quantity'] = np.where(raw_sales['Quantity'] > raw_sales['Quantity'].quantile(0.99), raw_sales['Quantity'].quantile(0.99), raw_sales['Quantity'])\n",
    "\n",
    "# Removing Duplicates\n",
    "cleaned_sales = raw_sales.drop_duplicates()\n",
    "\n",
    "# High Percentage of Missing Values\n",
    "threshold = 0.5\n",
    "columns_to_drop = [col for col in cleaned_sales.columns if cleaned_sales[col].isnull().sum() / len(cleaned_sales) > threshold and col not in primary_keys_sales]\n",
    "\n",
    "# Drop irrelevant, low variance, redundant, high correlation, and privacy-sensitive columns as per conditions\n",
    "cleaned_sales.drop(columns=set(columns_to_drop), inplace=True)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_sales.to_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_sales.csv', index=False)\n",
    "\n",
    "print(\"Sales data cleaning completed.\")\n",
    "\n",
    "# Load cleaned dataset\n",
    "sales = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_sales.csv')\n",
    "\n",
    "# Ensure 'Order Date' is in datetime format after cleaning\n",
    "sales['Order Date'] = pd.to_datetime(sales['Order Date'], errors='coerce')\n",
    "\n",
    "# EDA on Cleaned Data\n",
    "print(\"EDA on Cleaned Data\")\n",
    "print(sales.info())\n",
    "print(sales.head())\n",
    "print(sales.describe(include='all'))\n",
    "print(sales.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 10))  # Adjusted figure size to fit fewer plots\n",
    "\n",
    "# 1. Quantity Distribution (Cleaned Data)\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(sales['Quantity'].dropna(), bins=20, kde=True)\n",
    "plt.title('Quantity Distribution (Cleaned Data)')\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Sales by Product (Top 10 Products) (Cleaned Data)\n",
    "plt.subplot(2, 2, 2)\n",
    "if 'ProductKey' in sales.columns:\n",
    "    sns.countplot(y='ProductKey', data=sales, order=sales['ProductKey'].value_counts().index[:10])\n",
    "    plt.title('Top 10 Products by Sales Count (Cleaned Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Product')\n",
    "else:\n",
    "    print(\"Column 'ProductKey' is not present in the cleaned dataset.\")\n",
    "\n",
    "# 3. Sales by Store (Top 10 Stores) (Cleaned Data)\n",
    "plt.subplot(2, 2, 3)\n",
    "if 'StoreKey' in sales.columns:\n",
    "    sns.countplot(y='StoreKey', data=sales, order=sales['StoreKey'].value_counts().index[:10])\n",
    "    plt.title('Top 10 Stores by Sales Count (Cleaned Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Store')\n",
    "else:\n",
    "    print(\"Column 'StoreKey' is not present in the cleaned dataset.\")\n",
    "\n",
    "# Remove redundant plot for Sales Value Distribution (Cleaned Data)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional Plots (Cleaned Data)\n",
    "\n",
    "# 4. Sales over Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "if 'Order Date' in sales.columns:\n",
    "    sales['Order Date'].groupby(sales['Order Date'].dt.to_period('M')).count().plot()\n",
    "    plt.title('Sales Count Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales Count')\n",
    "else:\n",
    "    print(\"Column 'Order Date' is not present in the cleaned dataset.\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Quantity vs Sales Value\n",
    "plt.figure(figsize=(8, 6))\n",
    "if 'Sales Value' in sales.columns:\n",
    "    sns.scatterplot(x='Quantity', y='Sales Value', data=sales)\n",
    "    plt.title('Quantity vs Sales Value')\n",
    "    plt.xlabel('Quantity')\n",
    "    plt.ylabel('Sales Value')\n",
    "else:\n",
    "    print(\"Column 'Sales Value' is not present in the cleaned dataset.\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load raw dataset\n",
    "raw_stores = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\Stores.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# EDA on Raw Data\n",
    "print(\"EDA on Raw Data\")\n",
    "print(raw_stores.info())\n",
    "print(raw_stores.head())\n",
    "print(raw_stores.describe(include='all'))\n",
    "print(raw_stores.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Distribution of Square Meters (Raw Data)\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(raw_stores['Square Meters'].dropna(), bins=20, kde=True)\n",
    "plt.title('Distribution of Square Meters (Raw Data)')\n",
    "plt.xlabel('Square Meters')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Stores by Country (Top 10 Countries) (Raw Data)\n",
    "plt.subplot(2, 2, 2)\n",
    "if 'Country' in raw_stores.columns:\n",
    "    sns.countplot(y='Country', data=raw_stores, order=raw_stores['Country'].value_counts().index[:10])\n",
    "    plt.title('Top 10 Countries by Store Count (Raw Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Country')\n",
    "else:\n",
    "    print(\"Column 'Country' is not present in the raw dataset.\")\n",
    "\n",
    "# 3. Stores by State (Top 10 States) (Raw Data)\n",
    "plt.subplot(2, 2, 3)\n",
    "if 'State' in raw_stores.columns:\n",
    "    sns.countplot(y='State', data=raw_stores, order=raw_stores['State'].value_counts().index[:10])\n",
    "    plt.title('Top 10 States by Store Count (Raw Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('State')\n",
    "else:\n",
    "    print(\"Column 'State' is not present in the raw dataset.\")\n",
    "\n",
    "# 4. Open Date Distribution (Raw Data)\n",
    "plt.subplot(2, 2, 4)\n",
    "if 'Open Date' in raw_stores.columns:\n",
    "    sns.histplot(raw_stores['Open Date'].dropna(), bins=20, kde=True)\n",
    "    plt.title('Open Date Distribution (Raw Data)')\n",
    "    plt.xlabel('Open Date')\n",
    "    plt.ylabel('Frequency')\n",
    "else:\n",
    "    print(\"Column 'Open Date' is not present in the raw dataset.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data Cleaning\n",
    "# Handling Missing Values\n",
    "raw_stores['Country'].fillna('Unknown', inplace=True)\n",
    "raw_stores['State'].fillna('Unknown', inplace=True)\n",
    "raw_stores['Square Meters'].fillna(0, inplace=True)\n",
    "\n",
    "# Correcting Data Types\n",
    "raw_stores['Open Date'] = pd.to_datetime(raw_stores['Open Date'], errors='coerce')\n",
    "\n",
    "# Removing Duplicates (excluding primary key)\n",
    "cleaned_stores = raw_stores.drop_duplicates(subset=[col for col in raw_stores.columns if col not in ['StoreKey']])\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_stores.to_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_stores.csv', index=False)\n",
    "\n",
    "print(\"Stores data cleaning completed.\")\n",
    "\n",
    "# Load cleaned dataset\n",
    "stores = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_stores.csv')\n",
    "\n",
    "# Ensure 'Open Date' is in datetime format after cleaning\n",
    "stores['Open Date'] = pd.to_datetime(stores['Open Date'], errors='coerce')\n",
    "\n",
    "# EDA on Cleaned Data\n",
    "print(\"EDA on Cleaned Data\")\n",
    "print(stores.info())\n",
    "print(stores.head())\n",
    "print(stores.describe(include='all'))\n",
    "print(stores.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Distribution of Square Meters (Cleaned Data)\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(stores['Square Meters'].dropna(), bins=20, kde=True)\n",
    "plt.title('Distribution of Square Meters (Cleaned Data)')\n",
    "plt.xlabel('Square Meters')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Stores by Country (Top 10 Countries) (Cleaned Data)\n",
    "plt.subplot(2, 2, 2)\n",
    "if 'Country' in stores.columns:\n",
    "    sns.countplot(y='Country', data=stores, order=stores['Country'].value_counts().index[:10])\n",
    "    plt.title('Top 10 Countries by Store Count (Cleaned Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Country')\n",
    "else:\n",
    "    print(\"Column 'Country' is not present in the cleaned dataset.\")\n",
    "\n",
    "# 3. Stores by State (Top 10 States) (Cleaned Data)\n",
    "plt.subplot(2, 2, 3)\n",
    "if 'State' in stores.columns:\n",
    "    sns.countplot(y='State', data=stores, order=stores['State'].value_counts().index[:10])\n",
    "    plt.title('Top 10 States by Store Count (Cleaned Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('State')\n",
    "else:\n",
    "    print(\"Column 'State' is not present in the cleaned dataset.\")\n",
    "\n",
    "# 4. Open Date Distribution (Cleaned Data)\n",
    "plt.subplot(2, 2, 4)\n",
    "if 'Open Date' in stores.columns:\n",
    "    sns.histplot(stores['Open Date'].dropna(), bins=20, kde=True)\n",
    "    plt.title('Open Date Distribution (Cleaned Data)')\n",
    "    plt.xlabel('Open Date')\n",
    "    plt.ylabel('Frequency')\n",
    "else:\n",
    "    print(\"Column 'Open Date' is not present in the cleaned dataset.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load raw dataset\n",
    "raw_products = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\Products.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# EDA on Raw Data\n",
    "print(\"EDA on Raw Data\")\n",
    "print(raw_products.info())\n",
    "print(raw_products.head())\n",
    "print(raw_products.describe(include='all'))\n",
    "print(raw_products.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Distribution of Unit Cost USD (Raw Data)\n",
    "plt.subplot(2, 2, 1)\n",
    "if 'Unit Cost USD' in raw_products.columns:\n",
    "    sns.histplot(raw_products['Unit Cost USD'].str.replace('$', '').str.replace(',', '').dropna().astype(float), bins=20, kde=True)\n",
    "    plt.title('Distribution of Unit Cost USD (Raw Data)')\n",
    "    plt.xlabel('Unit Cost USD')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Distribution of Unit Price USD (Raw Data)\n",
    "plt.subplot(2, 2, 2)\n",
    "if 'Unit Price USD' in raw_products.columns:\n",
    "    sns.histplot(raw_products['Unit Price USD'].str.replace('$', '').str.replace(',', '').dropna().astype(float), bins=20, kde=True)\n",
    "    plt.title('Distribution of Unit Price USD (Raw Data)')\n",
    "    plt.xlabel('Unit Price USD')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "# 3. Product Count by Color (Raw Data)\n",
    "plt.subplot(2, 2, 3)\n",
    "if 'Color' in raw_products.columns:\n",
    "    sns.countplot(y='Color', data=raw_products, order=raw_products['Color'].value_counts().index[:10])\n",
    "    plt.title('Top 10 Colors by Product Count (Raw Data)')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Color')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "# Make a copy of raw_products to apply cleaning steps\n",
    "products = raw_products.copy()\n",
    "\n",
    "# Handling Missing Values\n",
    "products['Color'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Removing Duplicates\n",
    "products.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove currency symbols before converting to numeric\n",
    "for column in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    products[column] = products[column].str.replace('$', '').str.replace(',', '')\n",
    "\n",
    "# Correcting Data Types (e.g., converting cost and price to numeric)\n",
    "for column in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    try:\n",
    "        products[column] = pd.to_numeric(products[column], errors='coerce')\n",
    "        print(f\"Converted {column} to numeric successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {column} to numeric: {e}\")\n",
    "\n",
    "# Additional step to handle missing values in cost and price columns\n",
    "for column in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    if products[column].isnull().any():\n",
    "        products[column].fillna(products[column].median(), inplace=True)\n",
    "        print(f\"Filled missing values in {column} with the median.\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "products.to_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_products.csv', index=False)\n",
    "\n",
    "print(\"Products data cleaning completed.\")\n",
    "\n",
    "# Load cleaned dataset (if you want to reload it from the saved file, otherwise use the 'products' DataFrame directly)\n",
    "cleaned_products = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_products.csv')\n",
    "\n",
    "# EDA on Cleaned Data\n",
    "print(\"EDA on Cleaned Data\")\n",
    "print(cleaned_products.info())\n",
    "print(cleaned_products.head())\n",
    "print(cleaned_products.describe(include='all'))\n",
    "print(cleaned_products.isnull().sum())\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Distribution of Unit Cost USD (Cleaned Data)\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(cleaned_products['Unit Cost USD'].dropna(), bins=20, kde=True)\n",
    "plt.title('Distribution of Unit Cost USD (Cleaned Data)')\n",
    "plt.xlabel('Unit Cost USD')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Distribution of Unit Price USD (Cleaned Data)\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(cleaned_products['Unit Price USD'].dropna(), bins=20, kde=True)\n",
    "plt.title('Distribution of Unit Price USD (Cleaned Data)')\n",
    "plt.xlabel('Unit Price USD')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 3. Product Count by Color (Cleaned Data)\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.countplot(y='Color', data=cleaned_products, order=cleaned_products['Color'].value_counts().index[:10])\n",
    "plt.title('Top 10 Colors by Product Count (Cleaned Data)')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Color')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw dataset\n",
    "raw_exchange_rates = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\Exchange_Rates.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# EDA on Raw Data\n",
    "print(\"EDA on Raw Data\")\n",
    "print(raw_exchange_rates.info())\n",
    "print(raw_exchange_rates.head())\n",
    "print(raw_exchange_rates.describe(include='all'))\n",
    "print(raw_exchange_rates.isnull().sum())\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "# Make a copy of raw_exchange_rates to apply cleaning steps\n",
    "exchange_rates = raw_exchange_rates.copy()\n",
    "\n",
    "# Correcting Data Types\n",
    "exchange_rates['Date'] = pd.to_datetime(exchange_rates['Date'], errors='coerce')\n",
    "\n",
    "# Removing Duplicates\n",
    "exchange_rates.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save cleaned dataset\n",
    "exchange_rates.to_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_exchange_rates.csv', index=False)\n",
    "\n",
    "print(\"Exchange rates data cleaning completed.\")\n",
    "\n",
    "# Load cleaned dataset (if you want to reload it from the saved file, otherwise use the 'exchange_rates' DataFrame directly)\n",
    "cleaned_exchange_rates = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_exchange_rates.csv')\n",
    "\n",
    "# EDA on Cleaned Data\n",
    "print(\"EDA on Cleaned Data\")\n",
    "print(cleaned_exchange_rates.info())\n",
    "print(cleaned_exchange_rates.head())\n",
    "print(cleaned_exchange_rates.describe(include='all'))\n",
    "print(cleaned_exchange_rates.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned datasets\n",
    "customers = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_customers.csv', encoding='ISO-8859-1')\n",
    "sales = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_sales.csv', encoding='ISO-8859-1')\n",
    "stores = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_stores.csv', encoding='ISO-8859-1')\n",
    "products = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_products.csv', encoding='ISO-8859-1')\n",
    "exchange_rates = pd.read_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_exchange_rates.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Merge sales with customers\n",
    "sales_customers = pd.merge(sales, customers, how='left', left_on='CustomerKey', right_on='Customer_ID')\n",
    "\n",
    "# Merge sales_customers with stores\n",
    "sales_customers_stores = pd.merge(sales_customers, stores, how='left', left_on='StoreKey', right_on='StoreKey')\n",
    "\n",
    "# Merge sales_customers_stores with products\n",
    "sales_customers_stores_products = pd.merge(sales_customers_stores, products, how='left', left_on='ProductKey', right_on='ProductKey')\n",
    "\n",
    "# Optionally, merge with exchange rates if needed (e.g., if there are columns that need exchange rates)\n",
    "# Assuming you might want to join on a common date column, which isn't directly mentioned in the given datasets\n",
    "# sales_customers_stores_products = pd.merge(sales_customers_stores_products, exchange_rates, how='left', left_on='Date', right_on='Date')\n",
    "\n",
    "# Save the merged dataset\n",
    "sales_customers_stores_products.to_csv('D:\\\\Guvi\\\\projects\\\\Data Spark\\\\merged_data.csv', index=False)\n",
    "\n",
    "print(\"Data merging completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to the cleaned datasets\n",
    "customers_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_customers.csv'\n",
    "sales_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_sales.csv'\n",
    "stores_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_stores.csv'\n",
    "products_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_products.csv'\n",
    "exchange_rates_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_exchange_rates.csv'\n",
    "merged_data_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\merged_data.csv'\n",
    "\n",
    "# Path to the SQLite database\n",
    "db_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\Data_Spark.db'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Load each dataset\n",
    "customers = pd.read_csv(customers_path)\n",
    "sales = pd.read_csv(sales_path)\n",
    "stores = pd.read_csv(stores_path)\n",
    "products = pd.read_csv(products_path)\n",
    "exchange_rates = pd.read_csv(exchange_rates_path)\n",
    "merged_data = pd.read_csv(merged_data_path)\n",
    "\n",
    "# Insert each DataFrame into the SQLite database\n",
    "customers.to_sql('Customers', conn, if_exists='replace', index=False)\n",
    "sales.to_sql('Sales', conn, if_exists='replace', index=False)\n",
    "stores.to_sql('Stores', conn, if_exists='replace', index=False)\n",
    "products.to_sql('Products', conn, if_exists='replace', index=False)\n",
    "exchange_rates.to_sql('ExchangeRates', conn, if_exists='replace', index=False)\n",
    "merged_data.to_sql('MergedData', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(\"All datasets successfully stored in the SQLite database.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
